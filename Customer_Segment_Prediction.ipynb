{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWAOMH6GXl7zrZlsGRc2aY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YossefEFM/CodeClause_Customer_Segment_Prediction/blob/main/CodeClause_Customer_Segment_Prediction2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Author : ***Yossef Essam***"
      ],
      "metadata": {
        "id": "IX1ky952f3Sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All Importings"
      ],
      "metadata": {
        "id": "gB4hUOkTciDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import  confusion_matrix,classification_report"
      ],
      "metadata": {
        "id": "OHdnxFPGbQl5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data & Explore it"
      ],
      "metadata": {
        "id": "ufwT2U29cjmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data = pd.read_csv(\"/content/sample_data/ELD Service Provider Segmentation Dataset.csv\")\n",
        "# Explore Dataset\n",
        "print(Data.info())"
      ],
      "metadata": {
        "id": "KhGHbruDbToA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "vSmOUMJgcmU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # 1/ Cleaning the data from Missing values\n",
        "print(\"\\n Missing values : \")\n",
        "print(Data.isna().sum())\n",
        "Data.dropna(axis =0 , inplace=True)\n",
        "\n",
        "# 2/ Check duplicates\n",
        "print(\"\\n Duplicates  :\")\n",
        "print(Data.duplicated().sum())\n",
        "\n",
        "# 3/ Encoding Data\n",
        "labelencoder=LabelEncoder()\n",
        "Data['Territory'] = labelencoder.fit_transform(Data['Territory'])\n",
        "Data['Segment'] = labelencoder.fit_transform(Data['Segment'])\n",
        "\n",
        "\n",
        "# 4/ Removing Unwanted columns\n",
        "print(\"\\n\",Data.corr(),\"\\n\")\n",
        "Data.drop(columns= \"Customer Date\", inplace=True)\n",
        "\n",
        "print(Data.head())"
      ],
      "metadata": {
        "id": "Far7UPJCbUfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "hvkBaIzFctL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # 1/ Splitting data\n",
        "# X --> features , Y --> Label\n",
        "\n",
        "X = Data.drop(columns='Segment')\n",
        "Y = Data.Segment\n",
        "\n",
        "  # ** Split Features & Label to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20,  shuffle= True ,random_state= 1 )\n",
        " "
      ],
      "metadata": {
        "id": "O0iCsN5nbXnn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 2/ Calling Logistic regression\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "  # 3/ Train data\n",
        "log_reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Frr959FfcwyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # 4/ Predict\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        " # Confisuion Matrix\n",
        "#print(confusion_matrix(y_test, y_pred))\n",
        "# 5/ Report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print('report:', report, sep='\\n')\n"
      ],
      "metadata": {
        "id": "XxX6KHi3c1iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy in 20% of data to Test  ----> 78%\n"
      ],
      "metadata": {
        "id": "ek1QF_todKvu"
      }
    }
  ]
}